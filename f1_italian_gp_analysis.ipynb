{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOV6xzovQmGjSEt7VNgsEkF"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install fastf1 pandas numpy scikit-learn matplotlib seaborn joblib requests\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9P6EoyQZ9Jo",
        "outputId": "738ce1e4-bd95-45d4-97f4-f84d5a41d04f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastf1\n",
            "  Downloading fastf1-3.6.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from fastf1) (2.9.0.post0)\n",
            "Collecting rapidfuzz (from fastf1)\n",
            "  Downloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Collecting requests-cache>=1.0.0 (from fastf1)\n",
            "  Downloading requests_cache-1.2.1-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from fastf1) (1.16.1)\n",
            "Collecting timple>=0.1.6 (from fastf1)\n",
            "  Downloading timple-0.1.8-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting websockets<14,>=10.3 (from fastf1)\n",
            "  Downloading websockets-13.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->fastf1) (1.17.0)\n",
            "Requirement already satisfied: attrs>=21.2 in /usr/local/lib/python3.12/dist-packages (from requests-cache>=1.0.0->fastf1) (25.3.0)\n",
            "Collecting cattrs>=22.2 (from requests-cache>=1.0.0->fastf1)\n",
            "  Downloading cattrs-25.2.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests-cache>=1.0.0->fastf1) (4.4.0)\n",
            "Collecting url-normalize>=1.4 (from requests-cache>=1.0.0->fastf1)\n",
            "  Downloading url_normalize-2.2.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from cattrs>=22.2->requests-cache>=1.0.0->fastf1) (4.15.0)\n",
            "Downloading fastf1-3.6.1-py3-none-any.whl (148 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m148.6/148.6 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_cache-1.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.4/61.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timple-0.1.8-py3-none-any.whl (17 kB)\n",
            "Downloading websockets-13.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m165.0/165.0 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.14.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cattrs-25.2.0-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m70.0/70.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading url_normalize-2.2.1-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: websockets, url-normalize, rapidfuzz, cattrs, requests-cache, timple, fastf1\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 15.0.1\n",
            "    Uninstalling websockets-15.0.1:\n",
            "      Successfully uninstalled websockets-15.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dataproc-spark-connect 0.8.3 requires websockets>=14.0, but you have websockets 13.1 which is incompatible.\n",
            "google-adk 1.13.0 requires websockets<16.0.0,>=15.0.1, but you have websockets 13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cattrs-25.2.0 fastf1-3.6.1 rapidfuzz-3.14.1 requests-cache-1.2.1 timple-0.1.8 url-normalize-2.2.1 websockets-13.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GgePLEnxZbnW",
        "outputId": "cdb455af-3d73-41d5-9c7d-94e8ce436863"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "core           INFO \tLoading data for Monaco Grand Prix - Race [v3.6.1]\n",
            "INFO:fastf1.fastf1.core:Loading data for Monaco Grand Prix - Race [v3.6.1]\n",
            "req            INFO \tNo cached data found for session_info. Loading data...\n",
            "INFO:fastf1.fastf1.req:No cached data found for session_info. Loading data...\n",
            "_api           INFO \tFetching session info data...\n",
            "INFO:fastf1.api:Fetching session info data...\n",
            "req            INFO \tData has been written to cache!\n",
            "INFO:fastf1.fastf1.req:Data has been written to cache!\n",
            "req            INFO \tNo cached data found for driver_info. Loading data...\n",
            "INFO:fastf1.fastf1.req:No cached data found for driver_info. Loading data...\n",
            "_api           INFO \tFetching driver list...\n",
            "INFO:fastf1.api:Fetching driver list...\n",
            "req            INFO \tData has been written to cache!\n",
            "INFO:fastf1.fastf1.req:Data has been written to cache!\n",
            "req            INFO \tNo cached data found for session_status_data. Loading data...\n",
            "INFO:fastf1.fastf1.req:No cached data found for session_status_data. Loading data...\n",
            "_api           INFO \tFetching session status data...\n",
            "INFO:fastf1.api:Fetching session status data...\n",
            "req            INFO \tData has been written to cache!\n",
            "INFO:fastf1.fastf1.req:Data has been written to cache!\n",
            "req            INFO \tNo cached data found for lap_count. Loading data...\n",
            "INFO:fastf1.fastf1.req:No cached data found for lap_count. Loading data...\n",
            "_api           INFO \tFetching lap count data...\n",
            "INFO:fastf1.api:Fetching lap count data...\n",
            "req            INFO \tData has been written to cache!\n",
            "INFO:fastf1.fastf1.req:Data has been written to cache!\n",
            "req            INFO \tNo cached data found for track_status_data. Loading data...\n",
            "INFO:fastf1.fastf1.req:No cached data found for track_status_data. Loading data...\n",
            "_api           INFO \tFetching track status data...\n",
            "INFO:fastf1.api:Fetching track status data...\n",
            "req            INFO \tData has been written to cache!\n",
            "INFO:fastf1.fastf1.req:Data has been written to cache!\n",
            "req            INFO \tNo cached data found for _extended_timing_data. Loading data...\n",
            "INFO:fastf1.fastf1.req:No cached data found for _extended_timing_data. Loading data...\n",
            "_api           INFO \tFetching timing data...\n",
            "INFO:fastf1.api:Fetching timing data...\n",
            "_api           INFO \tParsing timing data...\n",
            "INFO:fastf1.api:Parsing timing data...\n",
            "req            INFO \tData has been written to cache!\n",
            "INFO:fastf1.fastf1.req:Data has been written to cache!\n",
            "req            INFO \tNo cached data found for timing_app_data. Loading data...\n",
            "INFO:fastf1.fastf1.req:No cached data found for timing_app_data. Loading data...\n",
            "_api           INFO \tFetching timing app data...\n",
            "INFO:fastf1.api:Fetching timing app data...\n",
            "req            INFO \tData has been written to cache!\n",
            "INFO:fastf1.fastf1.req:Data has been written to cache!\n",
            "core           INFO \tProcessing timing data...\n",
            "INFO:fastf1.fastf1.core:Processing timing data...\n",
            "req            INFO \tNo cached data found for car_data. Loading data...\n",
            "INFO:fastf1.fastf1.req:No cached data found for car_data. Loading data...\n",
            "_api           INFO \tFetching car data...\n",
            "INFO:fastf1.api:Fetching car data...\n",
            "_api           INFO \tParsing car data...\n",
            "INFO:fastf1.api:Parsing car data...\n",
            "req            INFO \tData has been written to cache!\n",
            "INFO:fastf1.fastf1.req:Data has been written to cache!\n",
            "req            INFO \tNo cached data found for position_data. Loading data...\n",
            "INFO:fastf1.fastf1.req:No cached data found for position_data. Loading data...\n",
            "_api           INFO \tFetching position data...\n",
            "INFO:fastf1.api:Fetching position data...\n",
            "_api           INFO \tParsing position data...\n",
            "INFO:fastf1.api:Parsing position data...\n",
            "_api        WARNING \tDriver 241: Position data is incomplete!\n",
            "WARNING:fastf1.api:Driver 241: Position data is incomplete!\n",
            "_api        WARNING \tDriver 242: Position data is incomplete!\n",
            "WARNING:fastf1.api:Driver 242: Position data is incomplete!\n",
            "_api        WARNING \tDriver 243: Position data is incomplete!\n",
            "WARNING:fastf1.api:Driver 243: Position data is incomplete!\n",
            "req            INFO \tData has been written to cache!\n",
            "INFO:fastf1.fastf1.req:Data has been written to cache!\n",
            "req            INFO \tNo cached data found for weather_data. Loading data...\n",
            "INFO:fastf1.fastf1.req:No cached data found for weather_data. Loading data...\n",
            "_api           INFO \tFetching weather data...\n",
            "INFO:fastf1.api:Fetching weather data...\n",
            "req            INFO \tData has been written to cache!\n",
            "INFO:fastf1.fastf1.req:Data has been written to cache!\n",
            "req            INFO \tNo cached data found for race_control_messages. Loading data...\n",
            "INFO:fastf1.fastf1.req:No cached data found for race_control_messages. Loading data...\n",
            "_api           INFO \tFetching race control messages...\n",
            "INFO:fastf1.api:Fetching race control messages...\n",
            "req            INFO \tData has been written to cache!\n",
            "INFO:fastf1.fastf1.req:Data has been written to cache!\n",
            "core           INFO \tFinished loading data for 20 drivers: ['16', '81', '55', '4', '63', '1', '44', '22', '23', '10', '14', '3', '77', '18', '2', '24', '31', '11', '27', '20']\n",
            "INFO:fastf1.fastf1.core:Finished loading data for 20 drivers: ['16', '81', '55', '4', '63', '1', '44', '22', '23', '10', '14', '3', '77', '18', '2', '24', '31', '11', '27', '20']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'list'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1862604822.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mweather_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0mforecast_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"2025-05-25 13:00:00\"\u001b[0m  \u001b[0;31m# 15:00 CEST local time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mforecast_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweather_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"list\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dt_txt\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mforecast_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0mrain_probability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforecast_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pop\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mforecast_data\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'list'"
          ]
        }
      ],
      "source": [
        "import fastf1\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Set style for professional visuals\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "class F1RacePredictor:\n",
        "    def __init__(self, cache_dir=\"f1_cache\"):\n",
        "        \"\"\"Initialize the F1 race predictor\"\"\"\n",
        "        fastf1.Cache.enable_cache(cache_dir)\n",
        "        self.data = None\n",
        "        self.model = None\n",
        "        self.feature_importance = None\n",
        "\n",
        "    def load_historical_data(self, year, race_number, session_type=\"R\"):\n",
        "        \"\"\"Load historical race data from FastF1\"\"\"\n",
        "        print(f\"Loading {year} race data...\")\n",
        "        session = fastf1.get_session(year, race_number, session_type)\n",
        "        session.load()\n",
        "\n",
        "        # Get lap data\n",
        "        laps = session.laps.copy()\n",
        "        laps = laps[[\"Driver\", \"LapTime\", \"Sector1Time\", \"Sector2Time\", \"Sector3Time\",\n",
        "                     \"Compound\", \"TyreLife\", \"FreshTyre\", \"Stint\", \"TrackStatus\", \"Position\"]]\n",
        "\n",
        "        # Only use green flag laps\n",
        "        laps = laps[laps[\"TrackStatus\"] == \"1\"]\n",
        "        laps.dropna(subset=[\"LapTime\", \"Sector1Time\", \"Sector2Time\", \"Sector3Time\"], inplace=True)\n",
        "\n",
        "        # Convert times to seconds\n",
        "        for col in [\"LapTime\", \"Sector1Time\", \"Sector2Time\", \"Sector3Time\"]:\n",
        "            laps[f\"{col} (s)\"] = laps[col].dt.total_seconds()\n",
        "\n",
        "        # Calculate consistency (standard deviation of lap times)\n",
        "        consistency = laps.groupby(\"Driver\")[\"LapTime (s)\"].std().reset_index()\n",
        "        consistency.columns = [\"Driver\", \"Consistency\"]\n",
        "\n",
        "        # Get average lap times by driver\n",
        "        avg_times = laps.groupby(\"Driver\").agg({\n",
        "            \"LapTime (s)\": \"mean\",\n",
        "            \"Sector1Time (s)\": \"mean\",\n",
        "            \"Sector2Time (s)\": \"mean\",\n",
        "            \"Sector3Time (s)\": \"mean\",\n",
        "            \"TyreLife\": \"mean\",\n",
        "            \"Stint\": \"max\",\n",
        "            \"Position\": \"min\"  # Best position achieved\n",
        "        }).reset_index()\n",
        "\n",
        "        # Merge with consistency data\n",
        "        self.historical_data = pd.merge(avg_times, consistency, on=\"Driver\")\n",
        "\n",
        "        # Add team information\n",
        "        driver_teams = {}\n",
        "        for driver in laps[\"Driver\"].unique():\n",
        "            try:\n",
        "                driver_teams[driver] = laps[laps[\"Driver\"] == driver].iloc[0][\"Team\"]\n",
        "            except:\n",
        "                driver_teams[driver] = \"Unknown\"\n",
        "\n",
        "        self.historical_data[\"Team\"] = self.historical_data[\"Driver\"].map(driver_teams)\n",
        "\n",
        "        print(f\"Loaded data for {len(self.historical_data)} drivers\")\n",
        "        return self.historical_data\n",
        "\n",
        "    def get_weather_data(self, lat, lon, race_date, api_key=None):\n",
        "        \"\"\"Get weather data from OpenWeatherMap API or use simulated data\"\"\"\n",
        "        # If no API key, use simulated data for Monza (typical early September weather)\n",
        "        if api_key is None:\n",
        "            print(\"Using simulated weather data for Monza\")\n",
        "            return {\n",
        "                \"temperature\": 26.5,  # Warm September day\n",
        "                \"humidity\": 65,\n",
        "                \"rain_probability\": 0.1,  # Low chance of rain\n",
        "                \"conditions\": \"Clear\"\n",
        "            }\n",
        "\n",
        "        try:\n",
        "            base_url = \"http://api.openweathermap.org/data/2.5/forecast\"\n",
        "            params = {\n",
        "                \"lat\": lat,\n",
        "                \"lon\": lon,\n",
        "                \"appid\": api_key,\n",
        "                \"units\": \"metric\"\n",
        "            }\n",
        "\n",
        "            response = requests.get(base_url, params=params)\n",
        "            weather_data = response.json()\n",
        "\n",
        "            # Find forecast closest to race time (typically 15:00 local)\n",
        "            race_time = f\"{race_date} 15:00:00\"\n",
        "            forecast_data = None\n",
        "\n",
        "            for forecast in weather_data[\"list\"]:\n",
        "                if forecast[\"dt_txt\"] == race_time:\n",
        "                    forecast_data = forecast\n",
        "                    break\n",
        "\n",
        "            if forecast_data:\n",
        "                weather_info = {\n",
        "                    \"temperature\": forecast_data[\"main\"][\"temp\"],\n",
        "                    \"humidity\": forecast_data[\"main\"][\"humidity\"],\n",
        "                    \"rain_probability\": forecast_data.get(\"pop\", 0),\n",
        "                    \"conditions\": forecast_data[\"weather\"][0][\"main\"]\n",
        "                }\n",
        "                return weather_info\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # Return default values if API call fails\n",
        "        return {\n",
        "            \"temperature\": 26.5,\n",
        "            \"humidity\": 65,\n",
        "            \"rain_probability\": 0.1,\n",
        "            \"conditions\": \"Clear\"\n",
        "        }\n",
        "\n",
        "    def create_features(self, qualifying_data, weather_data, team_performance):\n",
        "        \"\"\"Create feature set for prediction\"\"\"\n",
        "        # Start with qualifying data\n",
        "        features = qualifying_data.copy()\n",
        "\n",
        "        # Add weather data\n",
        "        features[\"Temperature\"] = weather_data[\"temperature\"]\n",
        "        features[\"Humidity\"] = weather_data[\"humidity\"]\n",
        "        features[\"RainProbability\"] = weather_data[\"rain_probability\"]\n",
        "        features[\"IsRainy\"] = 1 if weather_data[\"rain_probability\"] > 0.5 else 0\n",
        "\n",
        "        # Add team performance\n",
        "        features[\"TeamPerformance\"] = features[\"Team\"].map(team_performance)\n",
        "\n",
        "        # Merge with historical sector times\n",
        "        if self.historical_data is not None:\n",
        "            historical_avgs = self.historical_data.groupby(\"Driver\").agg({\n",
        "                \"Sector1Time (s)\": \"mean\",\n",
        "                \"Sector2Time (s)\": \"mean\",\n",
        "                \"Sector3Time (s)\": \"mean\",\n",
        "                \"Consistency\": \"mean\"\n",
        "            }).reset_index()\n",
        "\n",
        "            features = features.merge(historical_avgs, on=\"Driver\", how=\"left\")\n",
        "\n",
        "        return features\n",
        "\n",
        "    def train_model(self, features, target, test_size=0.2, random_state=42):\n",
        "        \"\"\"Train the prediction model\"\"\"\n",
        "        # Separate features and target\n",
        "        X = features.drop([\"Driver\", \"Team\", \"QualifyingTime (s)\"], axis=1, errors=\"ignore\")\n",
        "        y = target\n",
        "\n",
        "        # Handle missing values\n",
        "        imputer = SimpleImputer(strategy=\"mean\")\n",
        "        X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "        # Scale features\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "        # Split data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X_scaled, y, test_size=test_size, random_state=random_state\n",
        "        )\n",
        "\n",
        "        # Train model\n",
        "        self.model = GradientBoostingRegressor(\n",
        "            n_estimators=150,\n",
        "            learning_rate=0.1,\n",
        "            max_depth=4,\n",
        "            random_state=random_state\n",
        "        )\n",
        "\n",
        "        self.model.fit(X_train, y_train)\n",
        "\n",
        "        # Evaluate model\n",
        "        y_pred = self.model.predict(X_test)\n",
        "        mae = mean_absolute_error(y_test, y_pred)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        print(f\"Model Performance:\")\n",
        "        print(f\"MAE: {mae:.3f} seconds\")\n",
        "        print(f\"R¬≤ Score: {r2:.3f}\")\n",
        "\n",
        "        # Store feature importance\n",
        "        self.feature_importance = pd.DataFrame({\n",
        "            \"feature\": X.columns,\n",
        "            \"importance\": self.model.feature_importances_\n",
        "        }).sort_values(\"importance\", ascending=False)\n",
        "\n",
        "        return self.model, mae, r2\n",
        "\n",
        "    def predict_race(self, features):\n",
        "        \"\"\"Predict race results\"\"\"\n",
        "        # Prepare features for prediction\n",
        "        X = features.drop([\"Driver\", \"Team\", \"QualifyingTime (s)\"], axis=1, errors=\"ignore\")\n",
        "\n",
        "        # Handle missing values\n",
        "        imputer = SimpleImputer(strategy=\"mean\")\n",
        "        X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "        # Scale features\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.transform(X_imputed)\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = self.model.predict(X_scaled)\n",
        "\n",
        "        # Create results dataframe\n",
        "        results = features[[\"Driver\", \"Team\", \"QualifyingTime (s)\"]].copy()\n",
        "        results[\"PredictedRaceTime (s)\"] = predictions\n",
        "        results = results.sort_values(\"PredictedRaceTime (s)\")\n",
        "        results[\"PredictedPosition\"] = range(1, len(results) + 1)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def visualize_results(self, predictions, historical_data=None):\n",
        "        \"\"\"Create visualizations of the results\"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "        # Plot 1: Predicted race results\n",
        "        axes[0, 0].barh(predictions[\"Driver\"], predictions[\"PredictedRaceTime (s)\"],\n",
        "                       color=plt.cm.viridis(np.linspace(0, 1, len(predictions))))\n",
        "        axes[0, 0].set_xlabel(\"Predicted Race Time (s)\")\n",
        "        axes[0, 0].set_title(\"2025 Italian GP - Predicted Race Results\")\n",
        "        axes[0, 0].invert_yaxis()\n",
        "\n",
        "        # Plot 2: Qualifying vs Race pace\n",
        "        axes[0, 1].scatter(predictions[\"QualifyingTime (s)\"], predictions[\"PredictedRaceTime (s)\"])\n",
        "        for i, driver in enumerate(predictions[\"Driver\"]):\n",
        "            axes[0, 1].annotate(driver,\n",
        "                               (predictions[\"QualifyingTime (s)\"].iloc[i],\n",
        "                                predictions[\"PredictedRaceTime (s)\"].iloc[i]),\n",
        "                               xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
        "        axes[0, 1].set_xlabel(\"Qualifying Time (s)\")\n",
        "        axes[0, 1].set_ylabel(\"Predicted Race Time (s)\")\n",
        "        axes[0, 1].set_title(\"Qualifying vs Race Pace (Monza 2025)\")\n",
        "\n",
        "        # Plot 3: Feature importance\n",
        "        if self.feature_importance is not None:\n",
        "            axes[1, 0].barh(self.feature_importance[\"feature\"], self.feature_importance[\"importance\"])\n",
        "            axes[1, 0].set_xlabel(\"Importance\")\n",
        "            axes[1, 0].set_title(\"Feature Importance in Race Prediction\")\n",
        "\n",
        "        # Plot 4: Team performance comparison\n",
        "        team_avg = predictions.groupby(\"Team\")[\"PredictedRaceTime (s)\"].mean().sort_values()\n",
        "        axes[1, 1].barh(team_avg.index, team_avg.values)\n",
        "        axes[1, 1].set_xlabel(\"Average Predicted Race Time (s)\")\n",
        "        axes[1, 1].set_title(\"Team Performance Comparison (Monza 2025)\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(\"monza_2025_prediction_results.png\", dpi=300, bbox_inches=\"tight\")\n",
        "        plt.show()\n",
        "\n",
        "    def save_model(self, filepath):\n",
        "        \"\"\"Save the trained model to file\"\"\"\n",
        "        joblib.dump(self.model, filepath)\n",
        "        print(f\"Model saved to {filepath}\")\n",
        "\n",
        "    def load_model(self, filepath):\n",
        "        \"\"\"Load a trained model from file\"\"\"\n",
        "        self.model = joblib.load(filepath)\n",
        "        print(f\"Model loaded from {filepath}\")\n",
        "\n",
        "# Example usage for 2025 Italian GP\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize predictor\n",
        "    predictor = F1RacePredictor()\n",
        "\n",
        "    # Load historical data (2024 Italian GP for training)\n",
        "    # Note: You would need to check which round the 2024 Italian GP was\n",
        "    # For now, we'll assume it was round 15 of the 2024 season\n",
        "    historical_data = predictor.load_historical_data(2024, 15, \"R\")\n",
        "\n",
        "    # Define team performance scores (based on 2024 constructor standings)\n",
        "    # These would be updated with real 2024 data when available\n",
        "    team_performance = {\n",
        "        \"Red Bull\": 0.95,\n",
        "        \"Ferrari\": 0.90,  # Ferrari typically strong at Monza\n",
        "        \"McLaren\": 0.87,\n",
        "        \"Mercedes\": 0.85,\n",
        "        \"Aston Martin\": 0.78,\n",
        "        \"Alpine\": 0.72,\n",
        "        \"Williams\": 0.70,  # Williams often performs well at low-downforce tracks\n",
        "        \"RB\": 0.65,\n",
        "        \"Kick Sauber\": 0.62,\n",
        "        \"Haas\": 0.60\n",
        "    }\n",
        "\n",
        "    # Simulated qualifying data for 2025 Italian GP\n",
        "    # Monza is the \"Temple of Speed\" with very low downforce\n",
        "    qualifying_data = pd.DataFrame({\n",
        "        \"Driver\": [\"VER\", \"LEC\", \"SAI\", \"NOR\", \"PIA\", \"RUS\", \"HAM\", \"ALO\", \"ALB\", \"GAS\"],\n",
        "        \"Team\": [\"Red Bull\", \"Ferrari\", \"Ferrari\", \"McLaren\", \"McLaren\",\n",
        "                \"Mercedes\", \"Mercedes\", \"Aston Martin\", \"Williams\", \"Alpine\"],\n",
        "        \"QualifyingTime (s)\": [76.2, 76.5, 76.7, 76.8, 77.0, 77.1, 77.3, 77.5, 77.6, 77.8]\n",
        "    })\n",
        "\n",
        "    # Get weather data for Monza, Italy (September 7, 2025)\n",
        "    weather_data = predictor.get_weather_data(45.6156, 9.2814, \"2025-09-07\")\n",
        "\n",
        "    # Create features for prediction\n",
        "    features = predictor.create_features(qualifying_data, weather_data, team_performance)\n",
        "\n",
        "    # For training, we'll use historical lap times as target\n",
        "    target = historical_data[\"LapTime (s)\"]\n",
        "\n",
        "    # Train the model\n",
        "    model, mae, r2 = predictor.train_model(features, target)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = predictor.predict_race(features)\n",
        "\n",
        "    # Display results\n",
        "    print(\"\\nüèÅ Predicted 2025 Italian GP Results üèÅ\")\n",
        "    print(predictions[[\"Driver\", \"Team\", \"PredictedRaceTime (s)\", \"PredictedPosition\"]])\n",
        "\n",
        "    # Visualize results\n",
        "    predictor.visualize_results(predictions, historical_data)\n",
        "\n",
        "    # Save model for future use\n",
        "    predictor.save_model(\"monza_2025_predictor_model.pkl\")\n",
        "\n",
        "    # Compare with actual results (when available)\n",
        "    print(\"\\nNote: Once the actual 2025 Italian GP results are available,\")\n",
        "    print(\"you can compare these predictions with reality to validate the model!\")"
      ]
    }
  ]
}